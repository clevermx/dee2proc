{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dee2 tsv to srr h5   first version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "Unable to create file (unable to open file: name = 'D://datasets/DEE2//srr_files/ecoli_SRR_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mE:\\tools\\anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[0;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[0;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 408\u001b[1;33m                                swmr=swmr)\n\u001b[0m\u001b[0;32m    409\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\tools\\anaconda\\lib\\site-packages\\h5py\\_hl\\files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    177\u001b[0m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_EXCL\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    178\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'w'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m         \u001b[0mfid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mACC_TRUNC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfcpl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;31m# Open in append mode (read/write).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.create\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mOSError\u001b[0m: Unable to create file (unable to open file: name = 'D://datasets/DEE2//srr_files/ecoli_SRR_matrix.h5', errno = 2, error message = 'No such file or directory', flags = 13, o_flags = 302)"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D://datasets/DEE2/\"\n",
    "h5_file_name = cache_dir+\"/srr_files/\"+organism_name+ \"_SRR_matrix.h5\"\n",
    "meta_file_name = cache_dir+\"/metadata/\"+organism_name+\"_metadata.tsv\"\n",
    "data_file_name = cache_dir +\"/raw_files/\"+organism_name +\"_se.tsv\"\n",
    "with h5py.File(h5_file_name, 'w') as h5_file:\n",
    "    meta_grp = h5_file.create_group('meta')\n",
    "    info_grp = h5_file.create_group('info')\n",
    "    data_grp= h5_file.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=\"2020-02-23\")\n",
    "    meta_df=pd.read_csv(filepath_or_buffer=meta_file_name,sep=\"\\t\")\n",
    "    dt = h5py.special_dtype(vlen=np.str)\n",
    "    meta_grp.create_dataset('SRR_accession',data= np.array(meta_df[\"SRR_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=np.array(meta_df[\"GSE_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_instrument_model',data=np.array(meta_df[\"Model\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_last_update_date',data=np.array(meta_df[\"LoadDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_selection',data=np.array(meta_df[\"LibrarySelection\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_source',data=np.array(meta_df[\"LibrarySource\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_strategy',data=np.array(meta_df[\"LibraryStrategy\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',data=np.array(meta_df[\"ScientificName\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_series_id',data=np.array(meta_df[\"Sample_name\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_status',data=np.array(meta_df[\"Consent\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_submission_date',data=np.array(meta_df[\"ReleaseDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_taxid_ch1',data=np.array(meta_df[\"TaxID\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_quality',data=np.array(meta_df[\"QC_summary\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_title',data=np.array(meta_df[\"BioSample\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(len(meta_df[\"BioSample\"]),\"SRA\", dtype=dt))\n",
    "    h5_file.flush()\n",
    "    n_srr=len(meta_df[\"SRR_accession\"])\n",
    "    n_genes=0\n",
    "    genes= list()\n",
    "    with open(data_file_name, 'r') as data_file:\n",
    "        srr, gene_id, gene_count= data_file.readline().split(\"\\t\")\n",
    "        first_srr = srr\n",
    "        n_genes+=1\n",
    "        genes.append(gene_id)\n",
    "        while(True):\n",
    "            srr, gene_id, gene_count= data_file.readline().split(\"\\t\")\n",
    "            if (srr!=first_srr):\n",
    "                break\n",
    "            n_genes+=1\n",
    "            genes.append(gene_id)\n",
    "        meta_grp.create_dataset('genes',data=np.array(genes, dtype='S'))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_srr,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    h5_file.flush()\n",
    "    reader= pd.read_csv(data_file_name, sep='\\t', chunksize=n_genes,names=[\"srr\",\"gene\",\"count\"],iterator=True)\n",
    "    srr=0\n",
    "    chunk_size = 100    \n",
    "    while(srr<n_srr):\n",
    "        chunk = reader.get_chunk(chunk_size*n_genes)\n",
    "        last_ind = (srr+chunk_size) if (srr+chunk_size)<n_srr else n_srr\n",
    "        exp_data[srr: last_ind,0:n_genes]= chunk[\"count\"].values.reshape(last_ind-srr,n_genes)\n",
    "        h5_file.flush()      \n",
    "        srr+=chunk_size\n",
    "        if(srr%200==0):\n",
    "            print(srr/n_srr)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from bz2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02847380410022779\n",
      "0.05694760820045558\n",
      "0.08542141230068337\n",
      "0.11389521640091116\n",
      "0.14236902050113895\n",
      "0.17084282460136674\n",
      "0.19931662870159453\n",
      "0.22779043280182232\n",
      "0.25626423690205014\n",
      "0.2847380410022779\n",
      "0.3132118451025057\n",
      "0.3416856492027335\n",
      "0.3701594533029613\n",
      "0.39863325740318906\n",
      "0.4271070615034169\n",
      "0.45558086560364464\n",
      "0.48405466970387245\n",
      "0.5125284738041003\n",
      "0.541002277904328\n",
      "0.5694760820045558\n",
      "0.5979498861047836\n",
      "0.6264236902050114\n",
      "0.6548974943052391\n",
      "0.683371298405467\n",
      "0.7118451025056948\n",
      "0.7403189066059226\n",
      "0.7687927107061503\n",
      "0.7972665148063781\n",
      "0.8257403189066059\n",
      "0.8542141230068337\n",
      "0.8826879271070615\n",
      "0.9111617312072893\n",
      "0.9396355353075171\n",
      "0.9681093394077449\n",
      "0.9965831435079726\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#mklever_dee2 env\n",
    "import bz2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D://datasets/DEE2/\"\n",
    "h5_file_name = cache_dir+\"/srr_files/\"+organism_name+ \"_SRR_matrix.h5\"\n",
    "meta_file_name = cache_dir+\"/metadata/\"+organism_name+\"_metadata.tsv\"\n",
    "data_file_name = cache_dir +\"/raw_files/\"+organism_name +\"_se.tsv.bz2\"\n",
    "with h5py.File(h5_file_name, 'w') as h5_file:\n",
    "    meta_grp = h5_file.create_group('meta')\n",
    "    info_grp = h5_file.create_group('info')\n",
    "    data_grp= h5_file.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=\"2020-02-23\")\n",
    "    meta_df=pd.read_csv(filepath_or_buffer=meta_file_name,sep=\"\\t\")\n",
    "    dt = h5py.special_dtype(vlen=np.str)\n",
    "    meta_grp.create_dataset('SRR_accession',data= np.array(meta_df[\"SRR_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=np.array(meta_df[\"GEO_series\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_instrument_model',data=np.array(meta_df[\"Model\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_last_update_date',data=np.array(meta_df[\"LoadDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_selection',data=np.array(meta_df[\"LibrarySelection\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_source',data=np.array(meta_df[\"LibrarySource\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_strategy',data=np.array(meta_df[\"LibraryStrategy\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',data=np.array(meta_df[\"ScientificName\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_series_id',data=np.array(meta_df[\"Sample_name\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_status',data=np.array(meta_df[\"Consent\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_submission_date',data=np.array(meta_df[\"ReleaseDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_taxid_ch1',data=np.array(meta_df[\"TaxID\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_quality',data=np.array(meta_df[\"QC_summary\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_title',data=np.array(meta_df[\"BioSample\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(len(meta_df[\"BioSample\"]),\"SRA\", dtype=dt))\n",
    "    h5_file.flush()\n",
    "    n_srr=len(meta_df[\"SRR_accession\"])\n",
    "    n_genes=0\n",
    "    genes= list()\n",
    "    with bz2.BZ2File(data_file_name, 'r') as data_file:\n",
    "        srr, gene_id, gene_count= data_file.readline().split(b\"\\t\")\n",
    "        first_srr = srr\n",
    "        n_genes+=1\n",
    "        genes.append(gene_id)\n",
    "        while(True):\n",
    "            srr, gene_id, gene_count= data_file.readline().split(b\"\\t\")\n",
    "            if (srr!=first_srr):\n",
    "                break\n",
    "            n_genes+=1\n",
    "            genes.append(gene_id)\n",
    "        meta_grp.create_dataset('genes',data=np.array(genes, dtype='S'))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_srr,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    h5_file.flush()\n",
    "    reader= pd.read_csv(data_file_name, sep='\\t', chunksize=n_genes,names=[\"srr\",\"gene\",\"count\"],iterator=True)\n",
    "    srr=0\n",
    "    chunk_size = 100    \n",
    "    while(srr<n_srr):\n",
    "        chunk = reader.get_chunk(chunk_size*n_genes)\n",
    "        last_ind = (srr+chunk_size) if (srr+chunk_size)<n_srr else n_srr\n",
    "        exp_data[srr: last_ind,0:n_genes]= chunk[\"count\"].values.reshape(last_ind-srr,n_genes)\n",
    "        h5_file.flush()      \n",
    "        srr+=chunk_size\n",
    "        if(srr%200==0):\n",
    "            print(srr/n_srr)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "srr h5 to gsm h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.06263701847792046\n",
      "0.1252740369558409\n",
      "0.18791105543376135\n",
      "0.2505480739116818\n",
      "0.31318509238960224\n",
      "0.3758221108675227\n",
      "0.4384591293454432\n",
      "0.5010961478233636\n",
      "0.563733166301284\n",
      "0.6263701847792045\n",
      "0.689007203257125\n",
      "0.7516442217350454\n",
      "0.8142812402129659\n",
      "0.8769182586908864\n",
      "0.9395552771688067\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "def unique_fil(srr_group,gse_group,cur_gse,dset,ind):\n",
    "    cur_vals=srr_group[dset][ind]\n",
    "    if (len(np.unique(cur_vals))!=1):\n",
    "        gse_group[dset][cur_gse]=\",\".join(cur_vals)\n",
    "    else:\n",
    "        gse_group[dset][cur_gse]=cur_vals[0]\n",
    "\n",
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D:/datasets/DEE2/\"\n",
    "h5_srr_name = cache_dir+organism_name+ \"_SRR_matrix.h5\"\n",
    "h5_gsm_name = cache_dir+organism_name+ \"_matrix.h5\"\n",
    "gsm_map =defaultdict(list)\n",
    "now = datetime.datetime.now()\n",
    "gsm_list=[]\n",
    "with h5py.File(h5_srr_name, 'r') as h5_srr:\n",
    "    with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "        meta_grp = h5_gsm.create_group('meta')\n",
    "        info_grp = h5_gsm.create_group('info')\n",
    "        data_grp= h5_gsm.create_group('data')\n",
    "        info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "        info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "        n_genes =len(h5_srr[\"/meta/genes\"])\n",
    "        meta_grp.create_dataset('genes',data=h5_srr[\"/meta/genes\"])\n",
    "        for i_gsm in range(h5_srr[\"/meta/Sample_geo_accession\"].shape[0]):\n",
    "            row = h5_srr[\"/meta/Sample_geo_accession\"][i_gsm]\n",
    "            if ('GSM' in row):\n",
    "                gsm_map[row].append(i_gsm)                      \n",
    "        n_gsm=len(gsm_map)\n",
    "        dt = h5py.special_dtype(vlen=np.str)\n",
    "        meta_grp.create_dataset('Sample_geo_accession',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('SRR_accession',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_instrument_model',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_last_update_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_selection',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_source',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_strategy',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_organism_ch1',(n_gsm,),dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_series_id',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_status',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_submission_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_taxid_ch1',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_quality',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_title',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_type',data=np.full(n_gsm,\"SRA\", dtype =dt))\n",
    "        exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "        gsm_list = list(gsm_map.keys())\n",
    "        for i_gsm in  range(len(gsm_list)):\n",
    "            cur_gsm=gsm_list[i_gsm]\n",
    "            meta_grp[\"Sample_geo_accession\"][i_gsm]=cur_gsm\n",
    "            for key in h5_srr[\"meta\"]:\n",
    "                if (key == \"genes\"):\n",
    "                    continue\n",
    "                unique_fil(h5_srr[\"meta\"],meta_grp,i_gsm,key,gsm_map[cur_gsm])\n",
    "            exp_data[i_gsm,0:n_genes]=np.sum(h5_srr[\"/data/expression\"][gsm_map[cur_gsm],0:n_genes],0)\n",
    "            if(i_gsm%200==0):\n",
    "                print(i_gsm/len(gsm_list))\n",
    "        h5_gse.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get sparse matrices for srr and tx transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complete tx_to_gene matrix\n",
      "4322\n",
      "4322\n",
      "4322\n",
      "comlete meta reading\n",
      "7024\n",
      "3596\n",
      "start grouping\n",
      "groupped\n",
      "reordered\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import bz2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import isspmatrix_csr,csr_matrix,csc_matrix,issparse,isspmatrix_csr\n",
    "import math\n",
    "cache_dir=\"D:/datasets/DEE2/\"\n",
    "organism_name= 'ecoli'#'hsapiens' 'ecoli' mmusculus\n",
    "geo_acc_name = 'GSE_accession' # may be \"GSE_accession\" or \"Sample_name\"\n",
    "tx_info_file = cache_dir+\"TxInfo/\"+ organism_name+\"_TxInfo.tsv\"\n",
    "metadata_file = cache_dir+\"metadata/\"+ organism_name+\"_metadata.tsv\"\n",
    "tx_info=pd.read_csv(filepath_or_buffer=tx_info_file,sep=\"\\t\")\n",
    "tx_to_gene= dict(zip(tx_info[\"TxID\"],tx_info[\"GeneID\"]))\n",
    "tx_ind= {tx:ind for ind,tx in enumerate(tx_to_gene.keys())}\n",
    "gene_ind= {gene:ind for ind,gene in enumerate(pd.unique(tx_info[\"GeneID\"]))}\n",
    "tx_to_gene_matrix= sps.lil_matrix((len(tx_ind),len(gene_ind)))\n",
    "for tx_key in tx_to_gene:\n",
    "    tx_to_gene_matrix[tx_ind[tx_key],gene_ind[tx_to_gene[tx_key]]]=1\n",
    "print(\"complete tx_to_gene matrix\")\n",
    "print(len(gene_ind))\n",
    "print(len(tx_ind))\n",
    "print(len(tx_to_gene))\n",
    "#meta_df=pd.read_csv(filepath_or_buffer=metadata_file,sep=\"\\t\")   \n",
    "iter_meta = pd.read_csv(filepath_or_buffer=metadata_file,sep=\"\\t\", iterator=True, chunksize=1000)\n",
    "#meta_df = pd.concat([chunk[chunk[geo_acc_name].str.startswith('GSM')] for chunk in iter_meta])\n",
    "meta_df = pd.concat([chunk for chunk in iter_meta])\n",
    "print(\"comlete meta reading\")\n",
    "true_srr=len(meta_df)\n",
    "print(true_srr)\n",
    "meta_df=meta_df[meta_df[geo_acc_name].str.startswith('GSM')]\n",
    "n_srr= len(meta_df)\n",
    "print(n_srr)\n",
    "srr_to_gsm= dict(zip(meta_df[\"SRR_accession\"],meta_df[geo_acc_name]))\n",
    "srr_ind= {srr:ind for ind,srr in enumerate(srr_to_gsm.keys())}\n",
    "gsm_ind= {gsm:ind for ind,gsm in enumerate(pd.unique(meta_df[geo_acc_name]))}\n",
    "gsm_from_srr_matrix= sps.lil_matrix((len(gsm_ind),len(srr_ind)))\n",
    "for srr_key in srr_to_gsm:\n",
    "    gsm_from_srr_matrix[gsm_ind[srr_to_gsm[srr_key]],srr_ind[srr_key]]=1\n",
    "print(\"start grouping\")\n",
    "meta_df =meta_df.groupby(geo_acc_name).agg([lambda x: ';'.join(x)])\n",
    "print(\"groupped\")\n",
    "meta_df=meta_df.loc[gsm_ind.keys()] \n",
    "print(\"reordered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read dee2,transform via sparse matrices and write to h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start h5\n",
      "4322\n",
      "start cast matrices\n",
      "start process expression\n",
      "0.14236902050113895\n",
      "0.2847380410022779\n",
      "0.4271070615034169\n",
      "0.5694760820045558\n",
      "0.7118451025056948\n",
      "0.8542141230068337\n",
      "0.9965831435079726\n",
      "1\n",
      "Wall time: 40.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "from scipy.sparse import isspmatrix_csr,csr_matrix,csc_matrix,issparse,isspmatrix_csr\n",
    "data_file_name= cache_dir+\"raw_files/\"+organism_name+\"_ke.tsv.bz2\"\n",
    "#data_file_name=\"F://mmusculus_ke.tsv.bz2\"\n",
    "h5_gsm_name = cache_dir+organism_name+ \"_kalisto_matrix.h5\"\n",
    "now = datetime.datetime.now()\n",
    "print(\"start h5\")\n",
    "with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "    meta_grp = h5_gse.create_group('meta')\n",
    "    info_grp = h5_gse.create_group('info')\n",
    "    data_grp= h5_gse.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "    n_genes =len(gene_ind)\n",
    "    dt = h5py.special_dtype(vlen=np.str)\n",
    "    meta_grp.create_dataset('genes',data=gene_ind.keys(),dtype=dt)\n",
    "    n_gsm=len(gsm_ind)        \n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=gsm_ind.keys(), dtype =dt)\n",
    "    meta_grp.create_dataset('SRR_accession',data= np.array(meta_df[\"SRR_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_instrument_model',data=np.array(meta_df[\"Model\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_last_update_date',data=np.array(meta_df[\"LoadDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_selection',data=np.array(meta_df[\"LibrarySelection\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_source',data=np.array(meta_df[\"LibrarySource\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_strategy',data=np.array(meta_df[\"LibraryStrategy\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',data=np.array(meta_df[\"ScientificName\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_series_id',data=np.array(meta_df[\"Sample_name\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_status',data=np.array(meta_df[\"Consent\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_submission_date',data=np.array(meta_df[\"ReleaseDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_quality',data=np.array(meta_df[\"QC_summary\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_title',data=np.array(meta_df[\"BioSample\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(len(meta_df[\"BioSample\"]),\"SRA\", dtype=dt))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    processed_gse=0\n",
    "    srr_per_time=1000\n",
    "    row_length= len(tx_ind)\n",
    "    print(row_length)\n",
    "    iter_data = pd.read_csv(filepath_or_buffer=data_file_name,sep=\"\\t\", iterator=True, chunksize=srr_per_time*row_length,names=[\"srr\",\"tx\",\"ke\"])\n",
    "    proc_srr= 0\n",
    "    print(\"start cast matrices\")\n",
    "    gsm_from_srr_matrix=csr_matrix(gsm_from_srr_matrix)    \n",
    "    tx_to_gene_matrix=csr_matrix(tx_to_gene_matrix)\n",
    "    print(\"start process expression\")\n",
    "    for chunk in iter_data:\n",
    "        global_ids =[]\n",
    "        local_ids=[]\n",
    "        local_srr_ind= {srr:ind for ind,srr in enumerate(pd.unique(chunk['srr']))}\n",
    "        srr_count=len(local_srr_ind)\n",
    "        proc_srr=proc_srr+srr_count\n",
    "        for cur_srr in local_srr_ind:\n",
    "            try:\n",
    "                srr_id= srr_ind[cur_srr]\n",
    "                global_ids.append(srr_id)\n",
    "                local_ids.append(local_srr_ind[cur_srr])\n",
    "            except(KeyError):\n",
    "                continue\n",
    "        if local_ids:\n",
    "            raw_matrix= chunk[\"ke\"].values.astype(int).reshape(srr_count,row_length) #13.6 милисек\n",
    "            A=gsm_from_srr_matrix[:,global_ids]  #0.135 милисек\n",
    "            gsm_mask= [np.sum(x)>0 for x in A] #4 милисек\n",
    "            A = A.tocsr()  #очень быстро            \n",
    "            B=csr_matrix(raw_matrix[local_ids,]) #9 милисек\n",
    "            A = A.dot(B) #6 милисек\n",
    "            #print(isspmatrix_csr(A))\n",
    "            A = A.dot(tx_to_gene_matrix) #5 милисек\n",
    "            exp_data[gsm_mask== True,0:n_genes]+= A[gsm_mask== True,0:n_genes] #425 милисек\n",
    "        if proc_srr%500 ==0:\n",
    "            print(proc_srr/true_srr)\n",
    "    h5_gse.flush()\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEE2 STAR counts\n",
    "full processing from dee2 to h5 gse x gene file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "make gene index...\n",
      "gene quantity: 32833\n",
      "read meta file...\n",
      "real SRR quantity: 39774\n",
      "SRRs with gse: 26108\n",
      "make SRR and gsm indexes...\n",
      "GSMs quantity:\n",
      "start grouping...\n",
      "groupped\n",
      "reordered\n",
      "start h5...\n",
      "create file and write meta...\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'Sample_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3077\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3078\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sample_name'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2684\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2685\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mis_mi_columns\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2686\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2687\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2688\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_column\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m_getitem_multilevel\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2728\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2729\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_getitem_multilevel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2730\u001b[1;33m         \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2731\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2732\u001b[0m             \u001b[0mnew_columns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method)\u001b[0m\n\u001b[0;32m   2235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2236\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2237\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_level_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2239\u001b[0m             \u001b[1;31m# _get_level_indexer returns an empty slice if the key has\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\multi.py\u001b[0m in \u001b[0;36m_get_level_indexer\u001b[1;34m(self, key, level, indexer)\u001b[0m\n\u001b[0;32m   2494\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m             \u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlevel_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mloc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_loc\u001b[1;34m(self, key, method, tolerance)\u001b[0m\n\u001b[0;32m   3078\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3079\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3080\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_cast_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3081\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3082\u001b[0m         \u001b[0mindexer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtolerance\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtolerance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'Sample_name'"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "import bz2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "from scipy.sparse import isspmatrix_csr,csr_matrix,csc_matrix,issparse,isspmatrix_csr\n",
    "import math\n",
    "cache_dir=\"D://datasets/DEE2/\"\n",
    "organism_name= 'athaliana'#'hsapiens' 'ecoli' mmusculus athaliana\n",
    "geo_acc_name = 'GSE_accession' # may be \"GSE_accession\" or \"Sample_name\"\n",
    "metadata_file = cache_dir+\"metadata/\"+ organism_name+\"_meta_20200601.tsv\"\n",
    "data_file_name= cache_dir+\"raw_files/star_counts/\"+organism_name+\"_se_20200530.tsv.bz2\"\n",
    "h5_gsm_name = cache_dir+\"star_h5/\"+organism_name+ \"_star_matrix.h5\"\n",
    "gene_info_file_name =cache_dir+\"GeneInfo/\"+organism_name+\"_GeneInfo.tsv\"\n",
    "now = datetime.datetime.now()\n",
    "print(\"make gene index...\")\n",
    "gene_info=pd.read_csv(filepath_or_buffer=gene_info_file_name,sep=\"\\t\")\n",
    "gene_ind= {gene:ind for ind,gene in enumerate(gene_info[\"GeneID\"])}\n",
    "n_genes=len(gene_ind)\n",
    "print(\"gene quantity: \"+str(n_genes))\n",
    "print(\"read meta file...\")\n",
    "iter_meta = pd.read_csv(filepath_or_buffer=metadata_file,sep=\"\\t\", iterator=True, chunksize=1000)\n",
    "meta_df = pd.concat([chunk for chunk in iter_meta])\n",
    "true_srr=len(meta_df)\n",
    "print(\"real SRR quantity: \" +str(true_srr))\n",
    "meta_df=meta_df[meta_df[geo_acc_name].str.startswith('GSM')]\n",
    "n_srr= len(meta_df)\n",
    "print(\"SRRs with gse: \"+str(n_srr))\n",
    "print(\"make SRR and gsm indexes...\")\n",
    "srr_to_gsm= dict(zip(meta_df[\"SRR_accession\"],meta_df[geo_acc_name]))\n",
    "srr_ind= {srr:ind for ind,srr in enumerate(srr_to_gsm.keys())}\n",
    "gsm_ind= {gsm:ind for ind,gsm in enumerate(pd.unique(meta_df[geo_acc_name]))}\n",
    "n_gsm= len(gsm_ind)\n",
    "print(\"GSMs quantity:\" )\n",
    "gsm_from_srr_matrix= sps.lil_matrix((n_gsm,n_srr))\n",
    "for srr_key in srr_to_gsm:\n",
    "    gsm_from_srr_matrix[gsm_ind[srr_to_gsm[srr_key]],srr_ind[srr_key]]=1\n",
    "print(\"start grouping...\")\n",
    "meta_df =meta_df.groupby(geo_acc_name).agg([lambda x: ';'.join(x)])\n",
    "print(\"groupped\")\n",
    "meta_df=meta_df.loc[gsm_ind.keys()] \n",
    "print(\"reordered\")\n",
    "print(\"start h5...\")\n",
    "with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "    print(\"create file and write meta...\")\n",
    "    meta_grp = h5_gse.create_group('meta')\n",
    "    info_grp = h5_gse.create_group('info')\n",
    "    data_grp= h5_gse.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "    dt = h5py.special_dtype(vlen=np.str)\n",
    "    meta_grp.create_dataset('genes',data=gene_ind.keys(),dtype=dt)      \n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=gsm_ind.keys(), dtype =dt)\n",
    "    meta_grp.create_dataset('SRR_accession',data= np.array(meta_df[\"SRR_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_instrument_model',data=np.array(meta_df[\"Model\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_last_update_date',data=np.array(meta_df[\"LoadDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_selection',data=np.array(meta_df[\"LibrarySelection\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_source',data=np.array(meta_df[\"LibrarySource\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_strategy',data=np.array(meta_df[\"LibraryStrategy\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',data=np.array(meta_df[\"ScientificName\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_series_id',data=np.array(meta_df[\"Samplename\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_status',data=np.array(meta_df[\"Consent\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_submission_date',data=np.array(meta_df[\"ReleaseDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_quality',data=np.array(meta_df[\"QC_summary\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_title',data=np.array(meta_df[\"BioSample\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(len(meta_df[\"BioSample\"]),\"SRA\", dtype=dt))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    srr_per_time=1000\n",
    "    iter_data = pd.read_csv(filepath_or_buffer=data_file_name,sep=\"\\t\", iterator=True, chunksize=srr_per_time*n_genes,names=[\"srr\",\"gene\",\"se\"])\n",
    "    proc_srr= 0\n",
    "    gsm_from_srr_matrix=csr_matrix(gsm_from_srr_matrix)    \n",
    "    print(\"start process expression...\")\n",
    "    for chunk in iter_data:\n",
    "        global_ids =[]\n",
    "        local_ids=[]\n",
    "        local_srr_ind= {srr:ind for ind,srr in enumerate(pd.unique(chunk['srr']))}\n",
    "        srr_count=len(local_srr_ind)\n",
    "        proc_srr=proc_srr+srr_count\n",
    "        for cur_srr in local_srr_ind:\n",
    "            try:\n",
    "                srr_id= srr_ind[cur_srr]\n",
    "                global_ids.append(srr_id)\n",
    "                local_ids.append(local_srr_ind[cur_srr])\n",
    "            except(KeyError):\n",
    "                continue\n",
    "        if local_ids:\n",
    "            raw_matrix= chunk[\"se\"].values.astype(int).reshape(srr_count,n_genes) #13.6 милисек\n",
    "            A=gsm_from_srr_matrix[:,global_ids]  #0.135 милисек\n",
    "            gsm_mask= [np.sum(x)>0 for x in A] #4 милисек\n",
    "            A = A.tocsr()  #очень быстро            \n",
    "            B=csr_matrix(raw_matrix[local_ids,]) #9 милисек\n",
    "            A = A.dot(B) #6 милисек\n",
    "            exp_data[gsm_mask== True,0:n_genes]+= A[gsm_mask== True,0:n_genes] #425 милисек\n",
    "        if proc_srr%500 ==0:\n",
    "            print(proc_srr/true_srr)\n",
    "    h5_gse.flush()\n",
    "print(1)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex(levels=[['SRR_accession', 'QC_summary', 'SRX_accession', 'SRS_accession', 'SRP_accession', 'SampleName', 'ReleaseDate', 'LoadDate', 'download_path', 'LibraryStrategy', 'LibrarySelection', 'LibrarySource', 'LibraryLayout', 'Platform', 'Model', 'SRAStudy', 'Sample', 'BioSample', 'SampleType', 'ScientificName', 'Tumor', 'CenterName', 'Submission', 'Consent', 'RunHash', 'ReadHash'], ['<lambda>']],\n",
       "           labels=[[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4497\n",
      "4322\n",
      "['b4441', 'b0244', 'b4435', 'b3757', 'b1665', 'b4603', 'b3798', 'b4270', 'b4432', 'b2589', 'b3275', 'b4368', 'b1231', 'b4712', 'b4425', 'b2815', 'b0455', 'b4609', 'b2402', 'b2814', 'b2694', 'b4422', 'b4452', 'b3855', 'b4447', 'b0971', 'b3852', 'b4691', 'b4431', 'b4433', 'b3797', 'b4008', 'b4707', 'b0746', 'b4439', 'b0673', 'b3761', 'b1977', 'b3970', 'b2693', 'b3978', 'b4418', 'b2864', 'b4698', 'b4456', 'b4577', 'b3545', 'b2652', 'b0743', 'b3851', 'b2692', 'b2401', 'b3658', 'b3273', 'b0536', 'b0666', 'b0883', 'b4413', 'b2591', 'b1032', 'b4700', 'b4704', 'b4699', 'b3977', 'b4457', 'b4451', 'b3854', 'b1574', 'b1666', 'b0672', 'b4446', 'b2397', 'b4163', 'b3976', 'b3759', 'b2404', 'b3968', 'b4459', 'b2396', 'b4713', 'b0748', 'b0744', 'b4443', 'b0670', 'b4420', 'b2911', 'b0747', 'b4165', 'b4442', 'b4458', 'b4585', 'b3272', 'b4437', 'b4414', 'b0202', 'b4645', 'b2967', 'b3171', 'b4369', 'b0664', 'b2403', 'b3174', 'b2816', 'b3758', 'b3277', 'b0749', 'b0203', 'b0745', 'b4436', 'b3796', 'b4450', 'b3979', 'b1954', 'b4408', 'b1989', 'b4449', 'b0205', 'b1984', 'b2588', 'b3864', 'b2695', 'b0204', 'b0668', 'b4454', 'b2189', 'b4444', 'b3278', 'b0216', 'b0201', 'b1986', 'b4690', 'b4164', 'b3069', 'b4611', 'b4426', 'b4134', 'b4370', 'b3971', 'b0206', 'b0665', 'b1910', 'b3799', 'b3760', 'b4427', 'b3274', 'b4438', 'b4445', 'b4010', 'b3276', 'b3123', 'b1230', 'b4424', 'b4009', 'b4701', 'b4007', 'b2621', 'b4625', 'b4616', 'b4430', 'b2691', 'b1911', 'b4429', 'b4597', 'b4417', 'b4624', 'b3969', 'b4614', 'b2348', 'b3853', 'b2590', 'b1909', 'b4608', 'b1975', 'b3756', 'b4440']\n"
     ]
    }
   ],
   "source": [
    "test_genes= pd.unique(ecoli_dat[\"gene\"]).tolist()\n",
    "print(len(test_genes))\n",
    "print(len(gene_ind.keys()))\n",
    "print(list(set(test_genes)-set(gene_ind.keys())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SRR/h5 file with matrices Работает так же долго"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start h5\n",
      "4322\n",
      "start cast matrices\n",
      "start process expression\n",
      "0.14236902050113895\n",
      "0.2847380410022779\n",
      "0.4271070615034169\n",
      "0.5694760820045558\n",
      "0.7118451025056948\n",
      "0.8542141230068337\n",
      "0.9965831435079726\n",
      "1\n",
      "Wall time: 29 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import datetime\n",
    "from scipy.sparse import isspmatrix_csr,csr_matrix,csc_matrix\n",
    "data_file_name= cache_dir+\"raw_files/\"+organism_name+\"_ke.tsv.bz2\"\n",
    "#data_file_name=\"F://mmusculus_ke.tsv.bz2\"\n",
    "h5_gsm_name = cache_dir+organism_name+ \"_kalisto_SRR_matrix.h5\"\n",
    "now = datetime.datetime.now()\n",
    "print(\"start h5\")\n",
    "with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "    meta_grp = h5_gse.create_group('meta')\n",
    "    info_grp = h5_gse.create_group('info')\n",
    "    data_grp= h5_gse.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "    n_genes =len(gene_ind)\n",
    "    dt = h5py.special_dtype(vlen=np.str) \n",
    "    meta_grp.create_dataset('genes',data=srr_to_gsm.values(),dtype=dt)\n",
    "    meta_grp.create_dataset('SRR',data=srr_ind.keys(),dtype=dt)\n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=meta_df[geo_acc_name], dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_instrument_model',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_last_update_date',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_library_selection',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_library_source',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_library_strategy',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',(n_srr,),dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_series_id',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_status',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_submission_date',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_taxid_ch1',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_quality',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_title',(n_srr,), dtype =dt)\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(n_srr,\"SRA\", dtype =dt))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_srr,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    srr_per_time=1000\n",
    "    row_length= len(tx_ind)\n",
    "    print(row_length)\n",
    "    iter_data = pd.read_csv(filepath_or_buffer=data_file_name,sep=\"\\t\", iterator=True, chunksize=srr_per_time*row_length,names=[\"srr\",\"tx\",\"ke\"])\n",
    "    proc_srr= 0\n",
    "    print(\"start cast matrices\")  \n",
    "    tx_to_gene_matrix=csr_matrix(tx_to_gene_matrix)\n",
    "    print(\"start process expression\")\n",
    "    for chunk in iter_data:\n",
    "        global_ids =[]\n",
    "        local_ids=[]\n",
    "        local_srr_ind= {srr:ind for ind,srr in enumerate(pd.unique(chunk['srr']))}\n",
    "        srr_count=len(local_srr_ind)\n",
    "        proc_srr=proc_srr+srr_count\n",
    "        for cur_srr in sorted(local_srr_ind.keys()):\n",
    "            try:\n",
    "                srr_id= srr_ind[cur_srr]\n",
    "                global_ids.append(srr_id)\n",
    "                local_ids.append(local_srr_ind[cur_srr])\n",
    "            except(KeyError):\n",
    "                continue\n",
    "        \n",
    "        if local_ids:           \n",
    "            raw_matrix= chunk[\"ke\"].values.astype(int).reshape(srr_count,row_length)\n",
    "            A=csr_matrix(raw_matrix[local_ids,:])\n",
    "            A = A.dot(tx_to_gene_matrix)\n",
    "            exp_data[global_ids,0:n_genes]= exp_data[global_ids,0:n_genes]+A[:,0:n_genes]\n",
    "        if proc_srr%500 ==0:\n",
    "            print(proc_srr/true_srr)\n",
    "    h5_gse.flush()\n",
    "print(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DRR021384'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sort([x for x in local_srr_ind])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dee2 kalisto to h5 files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009882162459588544\n",
      "0.01976432491917709\n",
      "0.029646487378765633\n",
      "0.03952864983835418\n",
      "0.04941081229794272\n",
      "0.059292974757531265\n",
      "0.0691751372171198\n",
      "0.07905729967670835\n",
      "0.08893946213629689\n",
      "0.09882162459588544\n",
      "0.10870378705547398\n",
      "0.11858594951506253\n",
      "0.12846811197465108\n",
      "0.1383502744342396\n",
      "0.14823243689382815\n",
      "0.1581145993534167\n",
      "0.16799676181300524\n",
      "0.17787892427259377\n",
      "0.18776108673218234\n",
      "0.19764324919177087\n",
      "0.2075254116513594\n",
      "0.21740757411094797\n",
      "0.2272897365705365\n",
      "0.23717189903012506\n",
      "0.2470540614897136\n",
      "0.25693622394930216\n",
      "0.26681838640889066\n",
      "0.2767005488684792\n",
      "0.2865827113280678\n",
      "0.2964648737876563\n",
      "0.30634703624724485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;31m# === Check for zero-sized datasets =====\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             \u001b[1;31m# These are the only access methods NumPy allows for such objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mEllipsis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import bz2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sps\n",
    "import datetime\n",
    "import math\n",
    "cache_dir=\"D:/datasets/DEE2/\"\n",
    "organism_name= 'ecoli'\n",
    "tx_info_file = cache_dir+\"TxInfo/\"+ organism_name+\"_TxInfo.tsv\"\n",
    "metadata_file = cache_dir+\"metadata/\"+ organism_name+\"_metadata.tsv\"\n",
    "data_file_name= cache_dir+\"raw_files/\"+organism_name+\"_ke.tsv.bz2\"\n",
    "h5_gsm_name = cache_dir+organism_name+ \"_kalisto_matrix.h5\"\n",
    "#check txs\n",
    "#tx_dict=dict()\n",
    "#with open(tx_info_file, 'r') as info_file:\n",
    "#    for line in info_file:\n",
    "#        tx_id, gene_id, *tail= line.split(\"\\t\")\n",
    "#        try:\n",
    "#            if (tx_dict[tx_id] != gene_id):\n",
    "#                print(\"Error. tx in few genes\")\n",
    "#                break\n",
    "#        except(KeyError):\n",
    "#            tx_dict[tx_id] = gene_id\n",
    "#\n",
    "#            \n",
    "#print(len(tx_dict))\n",
    "\n",
    "\n",
    "tx_info=pd.read_csv(filepath_or_buffer=tx_info_file,sep=\"\\t\")\n",
    "tx_to_gene= dict(zip(tx_info[\"TxID\"],tx_info[\"GeneID\"]))\n",
    "genes= pd.unique(tx_info[\"GeneID\"])\n",
    "genes=dict(zip(genes,range(0,len(genes))))\n",
    "tx_g_shape = (len(tx_to_gene), len(genes))\n",
    "tx_to_gene_matrix= sps.coo_matrix(tx_g_shape)\n",
    "for (tx_key in tx_to_gene):\n",
    "    tx_to_gene_matrix[]\n",
    "\n",
    "meta_df=pd.read_csv(filepath_or_buffer=metadata_file,sep=\"\\t\")\n",
    "n_srr= len(meta_df)\n",
    "srr_to_gsm= dict(zip(meta_df[\"SRR_accession\"],meta_df[\"GSE_accession\"]))\n",
    "gsms= pd.unique([x for x in meta_df[\"GSE_accession\"] if ('GSM' in x)])\n",
    "gsms= dict(zip(gsms,range(0,len(gsms))))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "        meta_grp = h5_gse.create_group('meta')\n",
    "        info_grp = h5_gse.create_group('info')\n",
    "        data_grp= h5_gse.create_group('data')\n",
    "        info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "        info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "        n_genes =len(genes)\n",
    "        dt = h5py.special_dtype(vlen=np.str)\n",
    "        meta_grp.create_dataset('genes',data=genes.keys(),dtype=dt)\n",
    "        n_gsm=len(gsms)        \n",
    "        meta_grp.create_dataset('Sample_geo_accession',data=gsms.keys(), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_instrument_model',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_last_update_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_selection',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_source',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_strategy',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_organism_ch1',(n_gsm,),dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_series_id',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_status',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_submission_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_taxid_ch1',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_quality',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_title',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_type',data=np.full(n_gsm,\"SRA\", dtype =dt))\n",
    "        exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "        processed_gse=0\n",
    "        with bz2.open(data_file_name, 'rt') as data_file:\n",
    "            proc_srr=0\n",
    "            n_srr= 30357728\n",
    "            for line in data_file:\n",
    "                srr,tx,ke=line.split(\"\\t\")\n",
    "                proc_srr+=1\n",
    "                if(proc_srr%300000==0):\n",
    "                    print(proc_srr/n_srr)\n",
    "                cur_gsm=srr_to_gsm[srr]\n",
    "                try:\n",
    "                    gsm_ind=gsms[cur_gsm]\n",
    "                    cur_gene=tx_to_gene[tx]\n",
    "                    gene_ind=genes[cur_gene]\n",
    "                    exp_data[gsm_ind,gene_ind]=exp_data[gsm_ind,gene_ind]+math.floor(float(ke))    \n",
    "                except(KeyError):\n",
    "                    continue\n",
    "                            \n",
    "                \n",
    "        h5_gse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n",
      "<class 'dict'>\n",
      "<class 'numpy.ndarray'>\n",
      "7024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1111"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsms= pd.unique([x for x in meta_df[\"GSE_accession\"] if ('GSM' in x)])\n",
    "print(len(gsms))\n",
    "print(type(genes))\n",
    "print(type(gsms))\n",
    "gsms= dict(zip(gsms,range(0,len(gsms))))\n",
    "#print(gsms.keys())\n",
    "print(len(meta_df))\n",
    "genes=dict(zip(genes,range(0,len(genes))))\n",
    "\n",
    "meta_df[\"SampleName\"]\n",
    "float('3.1111\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qwe', 'ry']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d= defaultdict(list)\n",
    "d[\"qwe\"].append(1)\n",
    "d[\"qwe\"].append(10)\n",
    "d[\"ry\"].append(2)\n",
    "print(list(d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   digit  qwe\n",
      "0    111  aaa\n",
      "1    222  bbb\n",
      "2    333  ccc\n",
      "3    444  ddd\n",
      "4    555  eee\n",
      "   digit  qwe\n",
      "5    666  fff\n",
      "6    777  ggg\n",
      "7    888  hhh\n",
      "8    999  iii\n",
      "<pandas.io.parsers.TextFileReader object at 0x000001D4E811E390>\n",
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reader = pd.read_csv(\"D:/datasets/test.txt\", sep='\\t',names=[\"digit\",\"qwe\"], iterator=True)\n",
    "\n",
    "print(reader.get_chunk(5))\n",
    "print(reader.get_chunk(10))\n",
    "print(reader)\n",
    "print([1,2,3,4,5,5,6,78,8][1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сетов в матрице 167726\n",
      "генов в матрице 35238\n",
      "Sample_channel_count\n",
      "Sample_characteristics_ch1\n",
      "Sample_contact_address\n",
      "Sample_contact_city\n",
      "Sample_contact_country\n",
      "Sample_contact_department\n",
      "Sample_contact_email\n",
      "Sample_contact_institute\n",
      "Sample_contact_laboratory\n",
      "Sample_contact_name\n",
      "Sample_contact_phone\n",
      "Sample_contact_zip-postal_code\n",
      "Sample_data_processing\n",
      "Sample_data_row_count\n",
      "Sample_description\n",
      "Sample_extract_protocol_ch1\n",
      "Sample_geo_accession\n",
      "Sample_instrument_model\n",
      "Sample_last_update_date\n",
      "Sample_library_selection\n",
      "Sample_library_source\n",
      "Sample_library_strategy\n",
      "Sample_molecule_ch1\n",
      "Sample_organism_ch1\n",
      "Sample_platform_id\n",
      "Sample_relation\n",
      "Sample_series_id\n",
      "Sample_source_name_ch1\n",
      "Sample_status\n",
      "Sample_submission_date\n",
      "Sample_supplementary_file_1\n",
      "Sample_supplementary_file_2\n",
      "Sample_taxid_ch1\n",
      "Sample_title\n",
      "Sample_type\n",
      "gene_accession\n",
      "gene_chromosome\n",
      "gene_entrezid\n",
      "gene_hgnc\n",
      "gene_name\n",
      "gene_refseqid\n",
      "gene_synonym\n",
      "genes\n",
      "reads_aligned\n",
      "total_reads\n",
      "35238\n"
     ]
    }
   ],
   "source": [
    "arch_file = \"D:/datasets/ARCHS4_v7/human_matrix.h5\"\n",
    "with h5py.File(arch_file, 'a') as arch_7:\n",
    "    print(\"сетов в матрице \" + str(len(arch_7[\"data\"][\"expression\"])))\n",
    "    print( \"генов в матрице \" + str(len(arch_7[\"data\"][\"expression\"][1])))\n",
    "    for key in arch_7[\"meta\"].keys():\n",
    "        print(key)\n",
    "    print(len(arch_7[\"meta\"][\"genes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сетов в матрице 238522\n",
      "генов в матрице 35238\n",
      "Sample_channel_count\n",
      "Sample_characteristics_ch1\n",
      "Sample_contact_address\n",
      "Sample_contact_city\n",
      "Sample_contact_country\n",
      "Sample_contact_department\n",
      "Sample_contact_email\n",
      "Sample_contact_institute\n",
      "Sample_contact_laboratory\n",
      "Sample_contact_name\n",
      "Sample_contact_phone\n",
      "Sample_contact_zip-postal_code\n",
      "Sample_data_processing\n",
      "Sample_data_row_count\n",
      "Sample_description\n",
      "Sample_extract_protocol_ch1\n",
      "Sample_geo_accession\n",
      "Sample_instrument_model\n",
      "Sample_last_update_date\n",
      "Sample_library_selection\n",
      "Sample_library_source\n",
      "Sample_library_strategy\n",
      "Sample_molecule_ch1\n",
      "Sample_organism_ch1\n",
      "Sample_platform_id\n",
      "Sample_relation\n",
      "Sample_series_id\n",
      "Sample_source_name_ch1\n",
      "Sample_status\n",
      "Sample_submission_date\n",
      "Sample_supplementary_file_1\n",
      "Sample_supplementary_file_2\n",
      "Sample_taxid_ch1\n",
      "Sample_title\n",
      "Sample_type\n",
      "gene_accession\n",
      "gene_chromosome\n",
      "gene_entrezid\n",
      "gene_hgnc\n",
      "gene_name\n",
      "gene_refseqid\n",
      "gene_synonym\n",
      "genes\n",
      "reads_aligned\n",
      "reads_total\n",
      "35238\n"
     ]
    }
   ],
   "source": [
    "arch_file_8 = \"D:/datasets/phantasus_cache/archs4/human_matrix_8.h5\"\n",
    "with h5py.File(arch_file_8, 'a') as arch_8:\n",
    "    print(\"сетов в матрице \" + str(len(arch_8[\"data\"][\"expression\"])))\n",
    "    print( \"генов в матрице \" + str(len(arch_8[\"data\"][\"expression\"][1])))\n",
    "    for key in arch_8[\"meta\"].keys():\n",
    "        print(key)\n",
    "    print(len(arch_8[\"meta\"][\"genes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KeysView' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-34693910aa2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0march_7\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0march_8\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march_file_8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0march_7\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0march_8\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[0march_7\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'KeysView' object does not support indexing"
     ]
    }
   ],
   "source": [
    "arch_7= h5py.File(arch_file, 'a')\n",
    "arch_8= h5py.File(arch_file_8, 'a')\n",
    "\n",
    "arch_7[\"meta\"].keys()[arch_8[\"meta\"].keys()!= arch_7[\"meta\"].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
