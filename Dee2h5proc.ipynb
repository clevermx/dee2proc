{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv(filepath_or_buffer=meta_file_name,sep=\"\\t\")\n",
    "type(df[\"SRR_accession\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-970c36e97c84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhelp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreate_dataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'create_dataset' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dee2 tsv to srr h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mget_chunk\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m   1068\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1069\u001b[0m             \u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnrows\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_currow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1070\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1071\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1072\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1034\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'skipfooter not supported for iteration'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1035\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1036\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1037\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1038\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1846\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1847\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1848\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1849\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1850\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_column_data\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_tokens\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._convert_with_dtype\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\pandas\\core\\dtypes\\common.py\u001b[0m in \u001b[0;36mis_integer_dtype\u001b[1;34m(arr_or_dtype)\u001b[0m\n\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 811\u001b[1;33m \u001b[1;32mdef\u001b[0m \u001b[0mis_integer_dtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr_or_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    812\u001b[0m     \"\"\"\n\u001b[0;32m    813\u001b[0m     \u001b[0mCheck\u001b[0m \u001b[0mwhether\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mprovided\u001b[0m \u001b[0marray\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mdtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mof\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D://datasets/DEE2/\"\n",
    "h5_file_name = cache_dir+\"/srr_files/\"+organism_name+ \"_SRR_matrix.h5\"\n",
    "meta_file_name = cache_dir+\"/metadata/\"+organism_name+\"_metadata.tsv\"\n",
    "data_file_name = cache_dir +\"/raw_files/\"+organism_name +\"_se.tsv\"\n",
    "with h5py.File(h5_file_name, 'w') as h5_file:\n",
    "    meta_grp = h5_file.create_group('meta')\n",
    "    info_grp = h5_file.create_group('info')\n",
    "    data_grp= h5_file.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=\"2020-02-23\")\n",
    "    meta_df=pd.read_csv(filepath_or_buffer=meta_file_name,sep=\"\\t\")\n",
    "    dt = h5py.special_dtype(vlen=np.str)\n",
    "    meta_grp.create_dataset('SRR_accession',data= np.array(meta_df[\"SRR_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=np.array(meta_df[\"GSE_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_instrument_model',data=np.array(meta_df[\"Model\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_last_update_date',data=np.array(meta_df[\"LoadDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_selection',data=np.array(meta_df[\"LibrarySelection\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_source',data=np.array(meta_df[\"LibrarySource\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_strategy',data=np.array(meta_df[\"LibraryStrategy\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',data=np.array(meta_df[\"ScientificName\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_series_id',data=np.array(meta_df[\"Sample_name\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_status',data=np.array(meta_df[\"Consent\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_submission_date',data=np.array(meta_df[\"ReleaseDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_taxid_ch1',data=np.array(meta_df[\"TaxID\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_quality',data=np.array(meta_df[\"QC_summary\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_title',data=np.array(meta_df[\"BioSample\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(len(meta_df[\"BioSample\"]),\"SRA\", dtype=dt))\n",
    "    h5_file.flush()\n",
    "    n_srr=len(meta_df[\"SRR_accession\"])\n",
    "    n_genes=0\n",
    "    genes= list()\n",
    "    with open(data_file_name, 'r') as data_file:\n",
    "        srr, gene_id, gene_count= data_file.readline().split(\"\\t\")\n",
    "        first_srr = srr\n",
    "        n_genes+=1\n",
    "        genes.append(gene_id)\n",
    "        while(True):\n",
    "            srr, gene_id, gene_count= data_file.readline().split(\"\\t\")\n",
    "            if (srr!=first_srr):\n",
    "                break\n",
    "            n_genes+=1\n",
    "            genes.append(gene_id)\n",
    "        meta_grp.create_dataset('genes',data=np.array(genes, dtype='S'))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_srr,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    h5_file.flush()\n",
    "    reader= pd.read_csv(data_file_name, sep='\\t', chunksize=n_genes,names=[\"srr\",\"gene\",\"count\"],iterator=True)\n",
    "    srr=0\n",
    "    chunk_size = 100    \n",
    "    while(srr<n_srr):\n",
    "        chunk = reader.get_chunk(chunk_size*n_genes)\n",
    "        last_ind = (srr+chunk_size) if (srr+chunk_size)<n_srr else n_srr\n",
    "        exp_data[srr: last_ind,0:n_genes]= chunk[\"count\"].values.reshape(last_ind-srr,n_genes)\n",
    "        h5_file.flush()      \n",
    "        srr+=chunk_size\n",
    "        if(srr%200==0):\n",
    "            print(srr/n_srr)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from bz2 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02847380410022779\n",
      "0.05694760820045558\n",
      "0.08542141230068337\n",
      "0.11389521640091116\n",
      "0.14236902050113895\n",
      "0.17084282460136674\n",
      "0.19931662870159453\n",
      "0.22779043280182232\n",
      "0.25626423690205014\n",
      "0.2847380410022779\n",
      "0.3132118451025057\n",
      "0.3416856492027335\n",
      "0.3701594533029613\n",
      "0.39863325740318906\n",
      "0.4271070615034169\n",
      "0.45558086560364464\n",
      "0.48405466970387245\n",
      "0.5125284738041003\n",
      "0.541002277904328\n",
      "0.5694760820045558\n",
      "0.5979498861047836\n",
      "0.6264236902050114\n",
      "0.6548974943052391\n",
      "0.683371298405467\n",
      "0.7118451025056948\n",
      "0.7403189066059226\n",
      "0.7687927107061503\n",
      "0.7972665148063781\n",
      "0.8257403189066059\n",
      "0.8542141230068337\n",
      "0.8826879271070615\n",
      "0.9111617312072893\n",
      "0.9396355353075171\n",
      "0.9681093394077449\n",
      "0.9965831435079726\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "#mklever_dee2 env\n",
    "import bz2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D://datasets/DEE2/\"\n",
    "h5_file_name = cache_dir+\"/srr_files/\"+organism_name+ \"_SRR_matrix.h5\"\n",
    "meta_file_name = cache_dir+\"/metadata/\"+organism_name+\"_metadata.tsv\"\n",
    "data_file_name = cache_dir +\"/raw_files/\"+organism_name +\"_se.tsv.bz2\"\n",
    "with h5py.File(h5_file_name, 'w') as h5_file:\n",
    "    meta_grp = h5_file.create_group('meta')\n",
    "    info_grp = h5_file.create_group('info')\n",
    "    data_grp= h5_file.create_group('data')\n",
    "    info_grp.create_dataset('version', data=\"dee2_v1\")\n",
    "    info_grp.create_dataset('creation_date', data=\"2020-02-23\")\n",
    "    meta_df=pd.read_csv(filepath_or_buffer=meta_file_name,sep=\"\\t\")\n",
    "    dt = h5py.special_dtype(vlen=np.str)\n",
    "    meta_grp.create_dataset('SRR_accession',data= np.array(meta_df[\"SRR_accession\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_geo_accession',data=np.array(meta_df[\"GEO_series\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_instrument_model',data=np.array(meta_df[\"Model\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_last_update_date',data=np.array(meta_df[\"LoadDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_selection',data=np.array(meta_df[\"LibrarySelection\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_source',data=np.array(meta_df[\"LibrarySource\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_library_strategy',data=np.array(meta_df[\"LibraryStrategy\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_organism_ch1',data=np.array(meta_df[\"ScientificName\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_series_id',data=np.array(meta_df[\"Sample_name\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_status',data=np.array(meta_df[\"Consent\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_submission_date',data=np.array(meta_df[\"ReleaseDate\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_taxid_ch1',data=np.array(meta_df[\"TaxID\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_quality',data=np.array(meta_df[\"QC_summary\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_title',data=np.array(meta_df[\"BioSample\"], dtype=dt))\n",
    "    meta_grp.create_dataset('Sample_type',data=np.full(len(meta_df[\"BioSample\"]),\"SRA\", dtype=dt))\n",
    "    h5_file.flush()\n",
    "    n_srr=len(meta_df[\"SRR_accession\"])\n",
    "    n_genes=0\n",
    "    genes= list()\n",
    "    with bz2.BZ2File(data_file_name, 'r') as data_file:\n",
    "        srr, gene_id, gene_count= data_file.readline().split(b\"\\t\")\n",
    "        first_srr = srr\n",
    "        n_genes+=1\n",
    "        genes.append(gene_id)\n",
    "        while(True):\n",
    "            srr, gene_id, gene_count= data_file.readline().split(b\"\\t\")\n",
    "            if (srr!=first_srr):\n",
    "                break\n",
    "            n_genes+=1\n",
    "            genes.append(gene_id)\n",
    "        meta_grp.create_dataset('genes',data=np.array(genes, dtype='S'))\n",
    "    exp_data=data_grp.create_dataset(\"expression\", (n_srr,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "    h5_file.flush()\n",
    "    reader= pd.read_csv(data_file_name, sep='\\t', chunksize=n_genes,names=[\"srr\",\"gene\",\"count\"],iterator=True)\n",
    "    srr=0\n",
    "    chunk_size = 100    \n",
    "    while(srr<n_srr):\n",
    "        chunk = reader.get_chunk(chunk_size*n_genes)\n",
    "        last_ind = (srr+chunk_size) if (srr+chunk_size)<n_srr else n_srr\n",
    "        exp_data[srr: last_ind,0:n_genes]= chunk[\"count\"].values.reshape(last_ind-srr,n_genes)\n",
    "        h5_file.flush()      \n",
    "        srr+=chunk_size\n",
    "        if(srr%200==0):\n",
    "            print(srr/n_srr)\n",
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(h5_srr_name, 'r') as h5_srr:\n",
    "    print(h5_srr[\"/meta/Sample_geo_accession\"][0].startswith(b\"GSM\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'append'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-8a75dfa5a525>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"1\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'dict' object has no attribute 'append'"
     ]
    }
   ],
   "source": [
    "test=dict()\n",
    "test.append(\"1\",1)\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.02847380410022779\n",
      "0.05694760820045558\n",
      "0.08542141230068337\n",
      "0.11389521640091116\n",
      "0.14236902050113895\n",
      "0.17084282460136674\n",
      "0.19931662870159453\n",
      "0.22779043280182232\n",
      "0.25626423690205014\n",
      "0.2847380410022779\n",
      "0.3132118451025057\n",
      "0.3416856492027335\n",
      "0.3701594533029613\n",
      "0.39863325740318906\n",
      "0.4271070615034169\n",
      "0.45558086560364464\n",
      "0.48405466970387245\n",
      "0.5125284738041003\n",
      "0.541002277904328\n",
      "0.5694760820045558\n",
      "0.5979498861047836\n",
      "0.6264236902050114\n",
      "0.6548974943052391\n",
      "0.683371298405467\n",
      "0.7118451025056948\n",
      "0.7403189066059226\n",
      "0.7687927107061503\n",
      "0.7972665148063781\n",
      "0.8257403189066059\n",
      "0.8542141230068337\n",
      "0.8826879271070615\n",
      "0.9111617312072893\n",
      "0.9396355353075171\n",
      "0.9681093394077449\n",
      "0.9965831435079726\n"
     ]
    }
   ],
   "source": [
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D:/datasets/DEE2/\"\n",
    "h5_srr_name = cache_dir+organism_name+ \"_SRR_matrix.h5\"\n",
    "h5_gse_name = cache_dir+organism_name+ \"_matrix.h5\"\n",
    "gsm_map =dict()\n",
    "now = datetime.datetime.now()\n",
    "with h5py.File(h5_srr_name, 'r') as h5_srr:\n",
    "    with h5py.File(h5_gse_name, 'w') as h5_gse:\n",
    "        meta_grp = h5_gse.create_group('meta')\n",
    "        info_grp = h5_gse.create_group('info')\n",
    "        data_grp= h5_gse.create_group('data')\n",
    "        info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "        info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "        n_genes =len(h5_srr[\"/meta/genes\"])\n",
    "        meta_grp.create_dataset('genes',data=h5_srr[\"/meta/genes\"])\n",
    "        n_gsm=len(np.unique([x for x in h5_srr[\"/meta/Sample_geo_accession\"] if ('GSM' in x)]))\n",
    "        dt = h5py.special_dtype(vlen=np.str)\n",
    "        meta_grp.create_dataset('Sample_geo_accession',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_instrument_model',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_last_update_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_selection',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_source',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_strategy',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_organism_ch1',(n_gsm,),dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_series_id',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_status',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_submission_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_taxid_ch1',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_quality',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_title',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_type',data=np.full(n_gsm,\"SRA\", dtype =dt))\n",
    "        exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "        processed_gse=0\n",
    "        n_srr=len(h5_srr[\"/meta/SRR_accession\"])\n",
    "        for i in range(0,n_srr):\n",
    "            if(i%200==0):\n",
    "                print(i/n_srr)\n",
    "            cur_gse=processed_gse\n",
    "            if (h5_srr[\"/meta/Sample_geo_accession\"][i].startswith(\"GSM\")):\n",
    "                try:\n",
    "                    cur_gse=gsm_map[h5_srr[\"/meta/Sample_geo_accession\"][i]]                     \n",
    "                except KeyError:\n",
    "                    gsm_map[h5_srr[\"/meta/Sample_geo_accession\"][i]]=processed_gse\n",
    "                    processed_gse+=1\n",
    "                exp_data[cur_gse,0:n_genes]+=h5_srr[\"/data/expression\"][i,0:n_genes]\n",
    "                if (cur_gse==processed_gse-1):\n",
    "                    meta_grp[\"Sample_geo_accession\"][cur_gse]=h5_srr[\"/meta/Sample_geo_accession\"][i]\n",
    "                    meta_grp[\"Sample_instrument_model\"][cur_gse]=h5_srr[\"/meta/Sample_instrument_model\"][i]\n",
    "                    meta_grp[\"Sample_last_update_date\"][cur_gse]=h5_srr[\"/meta/Sample_last_update_date\"][i]\n",
    "                    meta_grp[\"Sample_library_selection\"][cur_gse]=h5_srr[\"/meta/Sample_library_selection\"][i]\n",
    "                    meta_grp[\"Sample_library_source\"][cur_gse]=h5_srr[\"/meta/Sample_library_source\"][i]\n",
    "                    meta_grp[\"Sample_library_strategy\"][cur_gse]=h5_srr[\"/meta/Sample_library_strategy\"][i]\n",
    "                    meta_grp[\"Sample_organism_ch1\"][cur_gse]=h5_srr[\"/meta/Sample_organism_ch1\"][i]\n",
    "                    meta_grp[\"Sample_status\"][cur_gse]=h5_srr[\"/meta/Sample_status\"][i]\n",
    "                    meta_grp[\"Sample_series_id\"][cur_gse]=h5_srr[\"/meta/Sample_series_id\"][i]\n",
    "                    meta_grp[\"Sample_submission_date\"][cur_gse]=h5_srr[\"/meta/Sample_submission_date\"][i]\n",
    "                    meta_grp[\"Sample_quality\"][cur_gse]=h5_srr[\"/meta/Sample_quality\"][i]\n",
    "                    meta_grp[\"Sample_title\"][cur_gse]=h5_srr[\"/meta/Sample_title\"][i]\n",
    "                    meta_grp[\"Sample_type\"][cur_gse]=h5_srr[\"/meta/Sample_type\"][i]\n",
    "        h5_gse.flush()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "srr h5 to gsm h5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.06263701847792046\n",
      "0.1252740369558409\n",
      "0.18791105543376135\n",
      "0.2505480739116818\n",
      "0.31318509238960224\n",
      "0.3758221108675227\n",
      "0.4384591293454432\n",
      "0.5010961478233636\n",
      "0.563733166301284\n",
      "0.6263701847792045\n",
      "0.689007203257125\n",
      "0.7516442217350454\n",
      "0.8142812402129659\n",
      "0.8769182586908864\n",
      "0.9395552771688067\n",
      "Wall time: 1min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from collections import defaultdict\n",
    "def unique_fil(srr_group,gse_group,cur_gse,dset,ind):\n",
    "    cur_vals=srr_group[dset][ind]\n",
    "    if (len(np.unique(cur_vals))!=1):\n",
    "        gse_group[dset][cur_gse]=\",\".join(cur_vals)\n",
    "    else:\n",
    "        gse_group[dset][cur_gse]=cur_vals[0]\n",
    "\n",
    "organism_name= 'ecoli'\n",
    "cache_dir=\"D:/datasets/DEE2/\"\n",
    "h5_srr_name = cache_dir+organism_name+ \"_SRR_matrix.h5\"\n",
    "h5_gsm_name = cache_dir+organism_name+ \"_matrix.h5\"\n",
    "gsm_map =defaultdict(list)\n",
    "now = datetime.datetime.now()\n",
    "gsm_list=[]\n",
    "with h5py.File(h5_srr_name, 'r') as h5_srr:\n",
    "    with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "        meta_grp = h5_gsm.create_group('meta')\n",
    "        info_grp = h5_gsm.create_group('info')\n",
    "        data_grp= h5_gsm.create_group('data')\n",
    "        info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "        info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "        n_genes =len(h5_srr[\"/meta/genes\"])\n",
    "        meta_grp.create_dataset('genes',data=h5_srr[\"/meta/genes\"])\n",
    "        for i_gsm in range(h5_srr[\"/meta/Sample_geo_accession\"].shape[0]):\n",
    "            row = h5_srr[\"/meta/Sample_geo_accession\"][i_gsm]\n",
    "            if ('GSM' in row):\n",
    "                gsm_map[row].append(i_gsm)                      \n",
    "        n_gsm=len(gsm_map)\n",
    "        dt = h5py.special_dtype(vlen=np.str)\n",
    "        meta_grp.create_dataset('Sample_geo_accession',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('SRR_accession',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_instrument_model',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_last_update_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_selection',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_source',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_strategy',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_organism_ch1',(n_gsm,),dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_series_id',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_status',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_submission_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_taxid_ch1',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_quality',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_title',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_type',data=np.full(n_gsm,\"SRA\", dtype =dt))\n",
    "        exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "        gsm_list = list(gsm_map.keys())\n",
    "        for i_gsm in  range(len(gsm_list)):\n",
    "            cur_gsm=gsm_list[i_gsm]\n",
    "            meta_grp[\"Sample_geo_accession\"][i_gsm]=cur_gsm\n",
    "            for key in h5_srr[\"meta\"]:\n",
    "                if (key == \"genes\"):\n",
    "                    continue\n",
    "                unique_fil(h5_srr[\"meta\"],meta_grp,i_gsm,key,gsm_map[cur_gsm])\n",
    "            exp_data[i_gsm,0:n_genes]=np.sum(h5_srr[\"/data/expression\"][gsm_map[cur_gsm],0:n_genes],0)\n",
    "            if(i_gsm%200==0):\n",
    "                print(i_gsm/len(gsm_list))\n",
    "        h5_gse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.009882162459588544\n",
      "0.01976432491917709\n",
      "0.029646487378765633\n",
      "0.03952864983835418\n",
      "0.04941081229794272\n",
      "0.059292974757531265\n",
      "0.0691751372171198\n",
      "0.07905729967670835\n",
      "0.08893946213629689\n",
      "0.09882162459588544\n",
      "0.10870378705547398\n",
      "0.11858594951506253\n",
      "0.12846811197465108\n",
      "0.1383502744342396\n",
      "0.14823243689382815\n",
      "0.1581145993534167\n",
      "0.16799676181300524\n",
      "0.17787892427259377\n",
      "0.18776108673218234\n",
      "0.19764324919177087\n",
      "0.2075254116513594\n",
      "0.21740757411094797\n",
      "0.2272897365705365\n",
      "0.23717189903012506\n",
      "0.2470540614897136\n",
      "0.25693622394930216\n",
      "0.26681838640889066\n",
      "0.2767005488684792\n",
      "0.2865827113280678\n",
      "0.2964648737876563\n",
      "0.30634703624724485\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mh5py\\_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mD:\\Tools\\anaconda\\lib\\site-packages\\h5py\\_hl\\dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;31m# === Check for zero-sized datasets =====\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 454\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mproduct\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    455\u001b[0m             \u001b[1;31m# These are the only access methods NumPy allows for such objects\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mEllipsis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "import bz2\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import datetime\n",
    "import math\n",
    "cache_dir=\"D:/datasets/DEE2/\"\n",
    "organism_name= 'ecoli'\n",
    "tx_info_file = cache_dir+\"TxInfo/\"+ organism_name+\"_TxInfo.tsv\"\n",
    "metadata_file = cache_dir+\"metadata/\"+ organism_name+\"_metadata.tsv\"\n",
    "data_file_name= cache_dir+\"raw_files/\"+organism_name+\"_ke.tsv.bz2\"\n",
    "h5_gsm_name = cache_dir+organism_name+ \"_kalisto_matrix.h5\"\n",
    "#check txs\n",
    "#tx_dict=dict()\n",
    "#with open(tx_info_file, 'r') as info_file:\n",
    "#    for line in info_file:\n",
    "#        tx_id, gene_id, *tail= line.split(\"\\t\")\n",
    "#        try:\n",
    "#            if (tx_dict[tx_id] != gene_id):\n",
    "#                print(\"Error. tx in few genes\")\n",
    "#                break\n",
    "#        except(KeyError):\n",
    "#            tx_dict[tx_id] = gene_id\n",
    "#\n",
    "#            \n",
    "#print(len(tx_dict))\n",
    "meta_df=pd.read_csv(filepath_or_buffer=metadata_file,sep=\"\\t\")\n",
    "srr_to_gsm= dict(zip(meta_df[\"SRR_accession\"],meta_df[\"GSE_accession\"]))\n",
    "tx_info=pd.read_csv(filepath_or_buffer=tx_info_file,sep=\"\\t\")\n",
    "tx_to_gene= dict(zip(tx_info[\"TxID\"],tx_info[\"GeneID\"]))\n",
    "n_srr= len(meta_df)\n",
    "gsms= pd.unique([x for x in meta_df[\"GSE_accession\"] if ('GSM' in x)])\n",
    "gsms= dict(zip(gsms,range(0,len(gsms))))\n",
    "genes= pd.unique(tx_info[\"GeneID\"])\n",
    "genes=dict(zip(genes,range(0,len(genes))))\n",
    "now = datetime.datetime.now()\n",
    "with h5py.File(h5_gsm_name, 'w') as h5_gse:\n",
    "        meta_grp = h5_gse.create_group('meta')\n",
    "        info_grp = h5_gse.create_group('info')\n",
    "        data_grp= h5_gse.create_group('data')\n",
    "        info_grp.create_dataset('version', data=\"dee2_gse_v1\")\n",
    "        info_grp.create_dataset('creation_date', data=now.strftime(\"%Y.%m.%d\"))\n",
    "        n_genes =len(genes)\n",
    "        dt = h5py.special_dtype(vlen=np.str)\n",
    "        meta_grp.create_dataset('genes',data=genes.keys(),dtype=dt)\n",
    "        n_gsm=len(gsms)        \n",
    "        meta_grp.create_dataset('Sample_geo_accession',data=gsms.keys(), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_instrument_model',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_last_update_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_selection',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_source',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_library_strategy',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_organism_ch1',(n_gsm,),dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_series_id',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_status',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_submission_date',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_taxid_ch1',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_quality',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_title',(n_gsm,), dtype =dt)\n",
    "        meta_grp.create_dataset('Sample_type',data=np.full(n_gsm,\"SRA\", dtype =dt))\n",
    "        exp_data=data_grp.create_dataset(\"expression\", (n_gsm,n_genes),dtype= 'i4')#, compression=\"gzip\", compression_opts=9)\n",
    "        processed_gse=0\n",
    "        with bz2.open(data_file_name, 'rt') as data_file:\n",
    "            proc_srr=0\n",
    "            n_srr= 30357728\n",
    "            for line in data_file:\n",
    "                srr,tx,ke=line.split(\"\\t\")\n",
    "                proc_srr+=1\n",
    "                if(proc_srr%300000==0):\n",
    "                    print(proc_srr/n_srr)\n",
    "                cur_gsm=srr_to_gsm[srr]\n",
    "                try:\n",
    "                    gsm_ind=gsms[cur_gsm]\n",
    "                    cur_gene=tx_to_gene[tx]\n",
    "                    gene_ind=genes[cur_gene]\n",
    "                    exp_data[gsm_ind,gene_ind]=exp_data[gsm_ind,gene_ind]+math.floor(float(ke))    \n",
    "                except(KeyError):\n",
    "                    continue\n",
    "                            \n",
    "                \n",
    "        h5_gse.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3193\n",
      "<class 'dict'>\n",
      "<class 'numpy.ndarray'>\n",
      "7024\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3.1111"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gsms= pd.unique([x for x in meta_df[\"GSE_accession\"] if ('GSM' in x)])\n",
    "print(len(gsms))\n",
    "print(type(genes))\n",
    "print(type(gsms))\n",
    "gsms= dict(zip(gsms,range(0,len(gsms))))\n",
    "#print(gsms.keys())\n",
    "print(len(meta_df))\n",
    "genes=dict(zip(genes,range(0,len(genes))))\n",
    "\n",
    "meta_df[\"SampleName\"]\n",
    "float('3.1111\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['qwe', 'ry']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "d= defaultdict(list)\n",
    "d[\"qwe\"].append(1)\n",
    "d[\"qwe\"].append(10)\n",
    "d[\"ry\"].append(2)\n",
    "print(list(d.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   digit  qwe\n",
      "0    111  aaa\n",
      "1    222  bbb\n",
      "2    333  ccc\n",
      "3    444  ddd\n",
      "4    555  eee\n",
      "   digit  qwe\n",
      "5    666  fff\n",
      "6    777  ggg\n",
      "7    888  hhh\n",
      "8    999  iii\n",
      "<pandas.io.parsers.TextFileReader object at 0x000001D4E811E390>\n",
      "[2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reader = pd.read_csv(\"D:/datasets/test.txt\", sep='\\t',names=[\"digit\",\"qwe\"], iterator=True)\n",
    "\n",
    "print(reader.get_chunk(5))\n",
    "print(reader.get_chunk(10))\n",
    "print(reader)\n",
    "print([1,2,3,4,5,5,6,78,8][1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сетов в матрице 167726\n",
      "генов в матрице 35238\n",
      "Sample_channel_count\n",
      "Sample_characteristics_ch1\n",
      "Sample_contact_address\n",
      "Sample_contact_city\n",
      "Sample_contact_country\n",
      "Sample_contact_department\n",
      "Sample_contact_email\n",
      "Sample_contact_institute\n",
      "Sample_contact_laboratory\n",
      "Sample_contact_name\n",
      "Sample_contact_phone\n",
      "Sample_contact_zip-postal_code\n",
      "Sample_data_processing\n",
      "Sample_data_row_count\n",
      "Sample_description\n",
      "Sample_extract_protocol_ch1\n",
      "Sample_geo_accession\n",
      "Sample_instrument_model\n",
      "Sample_last_update_date\n",
      "Sample_library_selection\n",
      "Sample_library_source\n",
      "Sample_library_strategy\n",
      "Sample_molecule_ch1\n",
      "Sample_organism_ch1\n",
      "Sample_platform_id\n",
      "Sample_relation\n",
      "Sample_series_id\n",
      "Sample_source_name_ch1\n",
      "Sample_status\n",
      "Sample_submission_date\n",
      "Sample_supplementary_file_1\n",
      "Sample_supplementary_file_2\n",
      "Sample_taxid_ch1\n",
      "Sample_title\n",
      "Sample_type\n",
      "gene_accession\n",
      "gene_chromosome\n",
      "gene_entrezid\n",
      "gene_hgnc\n",
      "gene_name\n",
      "gene_refseqid\n",
      "gene_synonym\n",
      "genes\n",
      "reads_aligned\n",
      "total_reads\n",
      "35238\n"
     ]
    }
   ],
   "source": [
    "arch_file = \"D:/datasets/ARCHS4_v7/human_matrix.h5\"\n",
    "with h5py.File(arch_file, 'a') as arch_7:\n",
    "    print(\"сетов в матрице \" + str(len(arch_7[\"data\"][\"expression\"])))\n",
    "    print( \"генов в матрице \" + str(len(arch_7[\"data\"][\"expression\"][1])))\n",
    "    for key in arch_7[\"meta\"].keys():\n",
    "        print(key)\n",
    "    print(len(arch_7[\"meta\"][\"genes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "сетов в матрице 238522\n",
      "генов в матрице 35238\n",
      "Sample_channel_count\n",
      "Sample_characteristics_ch1\n",
      "Sample_contact_address\n",
      "Sample_contact_city\n",
      "Sample_contact_country\n",
      "Sample_contact_department\n",
      "Sample_contact_email\n",
      "Sample_contact_institute\n",
      "Sample_contact_laboratory\n",
      "Sample_contact_name\n",
      "Sample_contact_phone\n",
      "Sample_contact_zip-postal_code\n",
      "Sample_data_processing\n",
      "Sample_data_row_count\n",
      "Sample_description\n",
      "Sample_extract_protocol_ch1\n",
      "Sample_geo_accession\n",
      "Sample_instrument_model\n",
      "Sample_last_update_date\n",
      "Sample_library_selection\n",
      "Sample_library_source\n",
      "Sample_library_strategy\n",
      "Sample_molecule_ch1\n",
      "Sample_organism_ch1\n",
      "Sample_platform_id\n",
      "Sample_relation\n",
      "Sample_series_id\n",
      "Sample_source_name_ch1\n",
      "Sample_status\n",
      "Sample_submission_date\n",
      "Sample_supplementary_file_1\n",
      "Sample_supplementary_file_2\n",
      "Sample_taxid_ch1\n",
      "Sample_title\n",
      "Sample_type\n",
      "gene_accession\n",
      "gene_chromosome\n",
      "gene_entrezid\n",
      "gene_hgnc\n",
      "gene_name\n",
      "gene_refseqid\n",
      "gene_synonym\n",
      "genes\n",
      "reads_aligned\n",
      "reads_total\n",
      "35238\n"
     ]
    }
   ],
   "source": [
    "arch_file_8 = \"D:/datasets/phantasus_cache/archs4/human_matrix_8.h5\"\n",
    "with h5py.File(arch_file_8, 'a') as arch_8:\n",
    "    print(\"сетов в матрице \" + str(len(arch_8[\"data\"][\"expression\"])))\n",
    "    print( \"генов в матрице \" + str(len(arch_8[\"data\"][\"expression\"][1])))\n",
    "    for key in arch_8[\"meta\"].keys():\n",
    "        print(key)\n",
    "    print(len(arch_8[\"meta\"][\"genes\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'KeysView' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-34693910aa2c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0march_7\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0march_8\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mh5py\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0march_file_8\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'a'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0march_7\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0march_8\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m!=\u001b[0m \u001b[0march_7\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"meta\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'KeysView' object does not support indexing"
     ]
    }
   ],
   "source": [
    "arch_7= h5py.File(arch_file, 'a')\n",
    "arch_8= h5py.File(arch_file_8, 'a')\n",
    "\n",
    "arch_7[\"meta\"].keys()[arch_8[\"meta\"].keys()!= arch_7[\"meta\"].keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
